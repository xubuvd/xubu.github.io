

# About Me
虚步, a Ph.D. student at BUPT. I am very fortunate to be advised by my advisor. My research is in the area of Vision and Language with a focus on Visual Dialogue. In particular, I am interested in building a visually-grounded conversational AI (social robot) that can see the world and talk with humans in natural language. Other interests include Language Grounding, Visual Reasoning, Visual Grounding, Visual Question Generation and Visual Dialog based Referring Expression.

<b>Now I'm doing research on GuessWhich and Visual Dialog(VisDial)</b>, please feel free to concat me with pangweitf@bupt.edu.cn or pangweitf@163.com if you have any questions or concerns.

# current Vision and Language tasks, focuses on Visual Dialogue
1. Multimodal Dialogs(MMD), AAAI 2018<br>
2. CoDraw, ACL 2019<br>
3. GuessWhich, AAAI 2017<br>
4. Multi-agent GuessWhich, AAMAS 2019<br>
5. GuessWhat?!, CVPR 2017<br>
6. EmbodiedQA, CVPR 2018<br>
7. VideoNavQA, BMVC 2019<br>
8. GuessNumber, SLT 2018<br>
9. VisDial, CVPR 2017<br>
10. Image-Grounded Conversations(IGC), CVPR 2017<br>
11. VDQG, ICCV 2017<br>
12. RDG-Image guessing game, LREC 2014<br>
13. Deal or No Deal, CoRR 2017<br>
14. Video-Grounded Dialogue Systems (VGDS), ACL 2019<br>
15. Vision-Language Navigation (VLN), CVPR 2018<br>
16. VQA<br>
